{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_size = 500\n",
    "hidden_node_features = 100\n",
    "\n",
    "class SummationMpnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_node_features = 500 #size from constant file\n",
    "        self.edge_features = 4\n",
    "        self.message_size = 100\n",
    "        self.message_passes = 3\n",
    "    def forward(self,nodes:tuple,edges:torch.tensor)->None:\n",
    "        adjacency = torch.sum(edges, dim=3)\n",
    "        print(\"adj is \",adjacency.shape)\n",
    "        (edge_batch_batch_idc,\n",
    "        edge_batch_node_idc,\n",
    "        edge_batch_nghb_idc) = adjacency.nonzero(as_tuple=True)\n",
    "        # print(\"edges various ares\",(edge_batch_batch_idc.shape,\n",
    "        # edge_batch_node_idc.shape,\n",
    "        # edge_batch_nghb_idc.shape))\n",
    "        #means picking out non zero waala indiced..gives connecting nodes\n",
    "        (node_batch_batch_idc,\n",
    "        node_batch_node_idc) = adjacency.sum(-1).nonzero(as_tuple=True)\n",
    "        print(\"nodes various ares\",(node_batch_batch_idc,node_batch_node_idc))\n",
    "\n",
    "        same_batch = node_batch_batch_idc.view(-1,1)== edge_batch_batch_idc\n",
    "        same_node  = node_batch_node_idc.view(-1, 1) == edge_batch_node_idc\n",
    "        print(\"same batch,node\",same_batch,   same_node)\n",
    "        message_summation_matrix = (same_batch * same_node).float()\n",
    "        print(\"message \",message_summation_matrix)\n",
    "        edge_batch_edges = edges[edge_batch_batch_idc, edge_batch_node_idc, edge_batch_nghb_idc, :]\n",
    "        print(\"edge_batch_edges \",edge_batch_edges.shape,'hello ',edges.shape)\n",
    "\n",
    "        hidden_nodes = torch.zeros(nodes.shape[0],\n",
    "                                   nodes.shape[1],\n",
    "                                   self.hidden_node_features,\n",
    "                                   device='cuda')\n",
    "        hidden_nodes[:nodes.shape[0], :nodes.shape[1], :nodes.shape[2]] = nodes.clone()#padding upto 13 nodes,with features to 100....we have only 9 features here\n",
    "        node_batch_nodes = hidden_nodes[node_batch_batch_idc, node_batch_node_idc, :]#picking out the same batch\n",
    "\n",
    "        print(\"yoyo \",node_batch_nodes.shape)\n",
    "        print(\"yoyo2\",hidden_nodes.shape)\n",
    "\n",
    "        for _ in range(self.message_passes):\n",
    "            edge_batch_nodes = hidden_nodes[edge_batch_batch_idc, edge_batch_node_idc, :]#getting hi  13*13*100\n",
    "\n",
    "            edge_batch_nghbs = hidden_nodes[edge_batch_batch_idc, edge_batch_nghb_idc, :]#getting neighs(hj)  13*13*1#why its 1\n",
    "            print(\"in message pass \",edge_batch_nghbs.shape, \"nodes \",edge_batch_nodes.shape)\n",
    "\n",
    "            message_terms    = self.message_terms(edge_batch_nodes,  \n",
    "                                                  edge_batch_nghbs,\n",
    "                                                  edge_batch_edges)\n",
    "\n",
    "            if len(message_terms.size()) == 1:  # if a single graph in batch\n",
    "                message_terms = message_terms.unsqueeze(0)\n",
    "\n",
    "            # the summation in eq. 1 of the NMPQC paper happens here\n",
    "            messages = torch.matmul(message_summation_matrix, message_terms)\n",
    "\n",
    "            node_batch_nodes = self.update(node_batch_nodes, messages)\n",
    "            hidden_nodes[node_batch_batch_idc, node_batch_node_idc, :] = node_batch_nodes.clone()\n",
    "\n",
    "        node_mask = adjacency.sum(-1) != 0\n",
    "        output    = self.readout(hidden_nodes, nodes, node_mask)\n",
    "        return hidden_nodes\n",
    "        #return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11828/498239923.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ASHISH\\AppData\\Local\\Temp/ipykernel_11828/498239923.py\"\u001b[1;36m, line \u001b[1;32m41\u001b[0m\n\u001b[1;33m    m1 = edges[:,i:,]*self.mlp1[]\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Attns2v(SummationMpnn):\n",
    "    \"\"\"\n",
    "    The \"message neural network\" model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.constants       = constants\n",
    "        message_weights      = torch.Tensor(message_size,\n",
    "                                            hidden_node_features,\n",
    "                                           4)\n",
    "        if True:#== \"cuda\":\n",
    "            message_weights = message_weights.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        self.message_weights = torch.nn.Parameter(message_weights)\n",
    "\n",
    "        self.gru             = torch.nn.GRUCell(\n",
    "            input_size=message_size,\n",
    "            hidden_size = hidden_node_features,\n",
    "            bias=True\n",
    "        )\n",
    "        #4 edge features\n",
    "        self.mlp1 = MLP(\n",
    "            in_features=100,\n",
    "            hidden_layer_sizes=[250] * 1,\n",
    "            out_features=100,\n",
    "            dropout_p=0.2\n",
    "        )\n",
    "        self.mlp2 = MLP(4,[250]*4,4,dropout_p=0)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        stdev = 1.0 / math.sqrt(self.message_weights.size(1))\n",
    "        self.message_weights.data.uniform_(-stdev, stdev)\n",
    "\n",
    "    def message_terms(self, nodes,node_neighbours,edges):\n",
    "        edges_v = edges.view(-1,1,1)#it gives value for edges.....type of edge..size->(6,4)->in molecule with 6 edges kind\n",
    "        neighs = edges_v*node_neighbours.view(-1,1,1)#multiplying each by this number\n",
    "        m1,b1 = [],[]\n",
    "        for i in range(4):\n",
    "            m1.append(edges[:,i,:]*self.mlp1[i](neighs[:,i,:]))\n",
    "            b1.append(edges[:,i,:]*self.mlp2[i](neighs[:,i,:]))\n",
    "        m1 = sum(m1)\n",
    "        b1 = sum(b1)\n",
    "        a = self.Softmax(b1)#check this Neigh(j) not understabbale\n",
    "        \n",
    "\n",
    "        return output\n",
    "\n",
    "    def update(self, nodes, messages):\n",
    "        return self.gru(messages, nodes)\n",
    "    \n",
    "    def readout(self,nodes_out,nodes_in):#two different readout will be here.....1st and 2nf is adp readout\n",
    "        \n",
    "        #mlp is single linear layer....signle hidden neural net\n",
    "        \n",
    "        p = self.emb(torch.cat[nodes_out,nodes_in])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a7aeb117152383494077b830ed8f2bcff9728640e9e954d18ee6388f442a456"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
